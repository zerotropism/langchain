{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773e4615",
   "metadata": {},
   "source": [
    "## Chains in LangChain\n",
    "Combines an LLM together with a prompt carrying a sequence of operations on text or data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951892b",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llassus/Developer/langchain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/llassus/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07JW9H4J1</td>\n",
       "      <td>Looks durable Charging is fine tooNo complains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B098NS6PVG</td>\n",
       "      <td>I ordered this cable to connect my phone to An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B096MSW6CT</td>\n",
       "      <td>Not quite durable and sturdy,https://m.media-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08HDJ86NZ</td>\n",
       "      <td>Good product,long wire,Charges good,Nice,I bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B08CF3B7N1</td>\n",
       "      <td>Bought this instead of original apple, does th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                     review_content\n",
       "0  B07JW9H4J1  Looks durable Charging is fine tooNo complains...\n",
       "1  B098NS6PVG  I ordered this cable to connect my phone to An...\n",
       "2  B096MSW6CT  Not quite durable and sturdy,https://m.media-a...\n",
       "3  B08HDJ86NZ  Good product,long wire,Charges good,Nice,I bou...\n",
       "4  B08CF3B7N1  Bought this instead of original apple, does th..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath = \"./data/amazon.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df = df[['product_id', 'review_content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b446fe4",
   "metadata": {},
   "source": [
    "### LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522263cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/stmkpc7x67x4qstrsg949vdc0000gn/T/ipykernel_25795/1800303320.py:4: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=model, temperature=0.9)\n",
      "/var/folders/1t/stmkpc7x67x4qstrsg949vdc0000gn/T/ipykernel_25795/1800303320.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n",
      "/var/folders/1t/stmkpc7x67x4qstrsg949vdc0000gn/T/ipykernel_25795/1800303320.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s brainstorm some names for a company specializing in Queen Size Sheet Sets. I\\'ll break down the suggestions into categories (Luxury, Modern, Cozy, Classic, Playful) and give explanations for each.  I\\'m also including a \"Bonus - Combination\" section at the end.  **Please read the notes at the very end - they\\'re important for checking trademark availability!**\\n\\n**1. Luxury & Premium Focused:**\\n\\n*   **Regal Slumber:** Evokes royalty and a luxurious sleep experience.\\n*   **Queen\\'s Rest:** Simple, elegant, and directly references the product.\\n*   **The Linen Atelier:** \"Atelier\" suggests craftsmanship and high-quality materials.\\n*   **Serene Haven:**  Focuses on the feeling of a peaceful sleep.\\n*   **Velvet Dream:** Associates the sheets with a luxurious feel.\\n*   **Aurum Sheets:** \"Aurum\" is Latin for gold, signifying premium quality.\\n*   **The Sleep Sanctuary:**  Positions the sheets as essential for restful sleep.\\n\\n**2. Modern & Minimalist:**\\n\\n*   **Queen & Co.:** Short, catchy, and modern.\\n*   **The Sheet Studio:**  Simple, professional, and direct.\\n*   **Loom & Thread:** Focuses on the process and materials.\\n*   **Q Sheets:** Very short and memorable (but might be *very* difficult to trademark - see notes at the end).\\n*   **Slumber Co.:** Clean, modern, and versatile.\\n*   **The Bed Collective:**  Implies a curated selection.\\n\\n**3. Cozy & Comfort Focused:**\\n\\n*   **Cloud Nine Sheets:**  Classic imagery of ultimate comfort.\\n*   **Hygge Home:**  \"Hygge\" (pronounced hoo-gah) is a Danish word for coziness and well-being.\\n*   **Snuggle Sheets:**  Directly communicates the feeling of comfort.\\n*   **Dream Weaver:** Suggests handcrafted and comforting sheets.\\n*   **The Cozy Queen:**  Friendly, approachable, and specific.\\n*   **Warm Embrace:** Focuses on the feeling of being enveloped in comfort.\\n\\n**4. Classic & Traditional:**\\n\\n*   **The Queen\\'s Linen:**  Elegant and timeless.\\n*   **Heritage Sheets:**  Implies quality and tradition.\\n*   **Royal Comfort:**  Combines luxury and relaxation.\\n*   **The Bedding House:**  Traditional and reliable.\\n*   **Sterling Slumber:** \"Sterling\" suggests high quality.\\n\\n**5. Playful & Unique:**\\n\\n*   **Queen Bee Sheets:**  Cute, memorable, and a little quirky.\\n*   **Sleepy Queen:**  Fun and approachable.\\n*   **The Sheet Happens:**  Playful and memorable (though could be seen as unprofessional by some).\\n*   **Dream Queen:**  Empowering and playful.\\n*   **Rest Easy Queen:**  Encouraging and fun.\\n\\n**Bonus - Combination Names (Mixing elements):**\\n\\n*   **Regal Slumber Co.:** (Luxury + Modern)\\n*   **Queen\\'s Heritage:** (Classic + Specific)\\n*   **The Cozy Queen Studio:** (Cozy + Modern)\\n*   **Loom & Regal:** (Modern + Luxury)\\n*   **Dream Queen Linens:** (Playful + Specific)\\n\\n\\n\\n**IMPORTANT NOTES - BEFORE YOU CHOOSE A NAME:**\\n\\n*   **Trademark Search is ESSENTIAL:**  This is the **MOST IMPORTANT** thing.  Just because a name *sounds* good doesn\\'t mean it\\'s available.  Go to the United States Patent and Trademark Office (USPTO) website ([https://www.uspto.gov/](https://www.uspto.gov/)) and perform a thorough trademark search.  Also search for the name online (Google, social media) to see if it\\'s already in use, even if not trademarked.\\n*   **Domain Name Availability:** Check if the corresponding domain name (.com, .net, etc.) is available.  Having a matching domain is very important for online presence.  Use a domain registrar like GoDaddy or Namecheap.\\n*   **Social Media Handles:**  Check if the name is available on social media platforms (Instagram, Facebook, Pinterest).\\n*   **Target Audience:** Consider who you\\'re selling to. A playful name might appeal to a younger audience, while a classic name might suit a more mature demographic.\\n*   **Memorability & Pronunciation:**  Choose a name that\\'s easy to remember and pronounce.\\n*   **Legal Advice:**  Consider consulting with a legal professional specializing in trademarks before finalizing your name. They can provide expert guidance.\\n*   **Avoid Generic Terms:** Names that are too generic (e.g., \"Queen Sheets\") are difficult to trademark and won\\'t stand out.\\n\\n\\n\\nTo help me narrow down the suggestions, could you tell me:\\n\\n*   **What is the general price point of your sheets?** (Luxury, Mid-Range, Budget-Friendly)\\n*   **Who is your target customer?** (Age, lifestyle, etc.)\\n*   **What is the overall brand \"feel\" you want to convey?**'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# redeclare the model\n",
    "model = \"gemma3:12b\"\n",
    "# reinstantiate the llm\n",
    "llm = ChatOllama(model=model, temperature=0.9)\n",
    "# create a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "# create a chain with the llm and prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# run the chain with a product name\n",
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f4a1f",
   "metadata": {},
   "source": [
    "### SimpleSequentialChain\n",
    "Simple input and simple output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redeclare the model\n",
    "model = \"gemma3:12b\"\n",
    "# reinstantiate the llm\n",
    "llm = ChatOllama(model=model, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f91de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/stmkpc7x67x4qstrsg949vdc0000gn/T/ipykernel_53380/1372733808.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_one = LLMChain(llm=llm, prompt=first_prompt)\n"
     ]
    }
   ],
   "source": [
    "# create a prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}? \\\n",
    "    Just output the best name you think of \\\n",
    "    without any explanation or extra text.\"\n",
    ")\n",
    "# and a chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sequential chain\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/stmkpc7x67x4qstrsg949vdc0000gn/T/ipykernel_53380/3263470644.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  display(Markdown(overall_simple_chain.run(product)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSlumberly\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHere are a few 20-word descriptions for Slumberly, catering to slightly different angles:\n",
      "\n",
      "**Option 1 (Focus on Comfort):**\n",
      "\n",
      "\"Slumberly creates luxurious, breathable bamboo bedding for the ultimate sleep experience. Soft, sustainable, and designed for blissful nights.\"\n",
      "\n",
      "**Option 1 (Focus on Sustainability):**\n",
      "\n",
      "\"Slumberly offers eco-friendly bamboo bedding, prioritizing comfort and sustainability. Sleep soundly knowing you're making a conscious choice.\"\n",
      "\n",
      "\n",
      "\n",
      "I hope these help!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are a few 20-word descriptions for Slumberly, catering to slightly different angles:\n",
       "\n",
       "**Option 1 (Focus on Comfort):**\n",
       "\n",
       "\"Slumberly creates luxurious, breathable bamboo bedding for the ultimate sleep experience. Soft, sustainable, and designed for blissful nights.\"\n",
       "\n",
       "**Option 1 (Focus on Sustainability):**\n",
       "\n",
       "\"Slumberly offers eco-friendly bamboo bedding, prioritizing comfort and sustainability. Sleep soundly knowing you're making a conscious choice.\"\n",
       "\n",
       "\n",
       "\n",
       "I hope these help!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "product = \"Queen Size Sheet Set\"\n",
    "display(Markdown(overall_simple_chain.run(product)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082dd198",
   "metadata": {},
   "source": [
    "### SequentialChain\n",
    "Mulitple inputs & outputs\n",
    "\n",
    "![sequentialchain.png](../img/sequentialchain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset base config\n",
    "from langchain.chains import SequentialChain\n",
    "# redeclare the model\n",
    "model = \"gemma3:12b\"\n",
    "# reinstantiate the llm\n",
    "llm = ChatOllama(model=model, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9bc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 0: translate original review from data into a different language for prompt template 1 to be useful\n",
    "reset_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Traduit cette √©valuation en Fran√ßais:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 0: input=Review, output=Reset review\n",
    "chain_zero = LLMChain(llm=llm, prompt=reset_prompt,\n",
    "                      output_key=\"Reset_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456aab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: translate Review to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Reset_Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2: summarize translated Review in one sentence\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f89e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: detect language of the original Review\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4 will take multiple inputs: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input = Review \n",
    "# and output = English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_zero, chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"Reset_Review\", \"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfa49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"It's a good product.,Like,Very good item strong and useful USB cableValue for moneyThanks to amazon and producer,https://m.media-amazon.com/images/I/51112ZRE-1L._SY88.jpg,Good,Nice product and useful product,-,Sturdy but does not support 33w charging\",\n",
       " 'Reset_Review': 'Voici une traduction de l\\'√©valuation en fran√ßais, en essayant de conserver le ton et le style originaux :\\n\\n\"C\\'est un bon produit. J\\'aime, tr√®s bon article, c√¢ble USB solide et utile. Bon rapport qualit√©/prix. Merci √† Amazon et au fabricant. [Lien vers l\\'image]. Bon, un produit sympa et utile. - Solide mais ne supporte pas la charge rapide 33W.\"\\n\\n**Quelques remarques sur la traduction:**\\n\\n* \"Like\" a √©t√© traduit par \"J\\'aime\" pour refl√©ter le sentiment d\\'appr√©ciation.\\n* \"Value for money\" est devenu \"Bon rapport qualit√©/prix\".\\n* Le lien vers l\\'image a √©t√© conserv√© comme tel.\\n* Le tiret \"-\" a √©t√© conserv√© pour s√©parer les deux derni√®res phrases.\\n* \"Sturdy\" est traduit par \"Solide\".\\n* \"Does not support 33w charging\" est traduit par \"ne supporte pas la charge rapide 33W.\"  On ajoute \"rapide\" pour plus de clart√©.',\n",
       " 'English_Review': 'Here\\'s a translation of the French review, attempting to maintain the original tone and style:\\n\\n\"It\\'s a good product. I like it, a very good item, a sturdy and useful USB cable. Good value for money. Thank you to Amazon and the manufacturer. [Link to image]. Overall, a nice and useful product - Sturdy, but doesn\\'t support 33W fast charging.\"\\n',\n",
       " 'summary': \"This is a sturdy and useful USB cable offering good value, though it doesn't support 33W fast charging.\",\n",
       " 'followup_message': 'Okay, here are a few follow-up responses, each aiming for a more polished, native-speaker tone while still retaining the original sentiment. I\\'ll offer three options ‚Äì a brief, a moderate, and a more detailed response ‚Äì so you can choose the one that best fits the context.  I\\'ve also included explanations of *why* the changes were made after each option.\\n\\n**Option 1: Brief & Concise**\\n\\n\"It\\'s a solid cable and a good value for the price, though the lack of 33W fast charging is a limitation.\"\\n\\n**Explanation of Changes:**\\n\\n*   **\"It\\'s a solid cable\"** replaces \"This is a sturdy and useful product\" - more concise and natural phrasing.\\n*   **\"good value for the price\"** is a common idiom replacing \"good value\".\\n*   **\"limitation\"** is a more sophisticated word than \"doesn\\'t support\".\\n*   Removed the redundant \"like\".\\n*   Combined the two sentences for better flow.\\n\\n**Option 2: Moderate Detail**\\n\\n\"This is a well-made and practical USB cable, offering good value for money. It\\'s a reliable choice for everyday use, however, it\\'s worth noting that it doesn\\'t support the faster 33W charging speeds.\"\\n\\n**Explanation of Changes:**\\n\\n*   **\"well-made and practical\"** replaces \"sturdy and useful\" - expands on the positive attributes while sounding more natural.\\n*   **\"value for money\"** is a standard expression.\\n*   **\"reliable choice for everyday use\"** adds a bit more context and detail.\\n*   **\"it\\'s worth noting that...\"** is a smoother, more polite way to introduce the limitation.\\n*   Removed the filler word \"like\".\\n*   Sentence structure improved for better readability.\\n\\n**Option 3: More Detailed & Explanatory**\\n\\n\"This USB cable feels robust and serves its purpose well, representing a good value option. It\\'s a dependable choice for charging and data transfer. However, if you\\'re looking for the fastest possible charging speeds ‚Äì specifically 33W ‚Äì you‚Äôre likely to find this cable isn‚Äôt quite up to the task.\"\\n\\n**Explanation of Changes:**\\n\\n*   **\"feels robust and serves its purpose well\"** - replaces the simpler description.\\n*   **\"representing a good value option\"** ‚Äì a more formal and descriptive phrase.\\n*   **\"dependable choice for charging and data transfer\"** ‚Äì expands on the uses.\\n*   **\"if you\\'re looking for the fastest possible charging speeds‚Ä¶\"** - provides context and clarifies the limitation.\\n*   **\"you‚Äôre likely to find this cable isn‚Äôt quite up to the task\"** -  a more nuanced and less direct way of saying it doesn\\'t support the feature.\\n*   Removed filler words and improved sentence flow for a more professional tone.\\n\\n\\n\\nTo help me tailor the response even further, could you tell me:\\n\\n*   What is the context of this review? (e.g., a product listing, a blog post, a forum comment)\\n*   Who is the intended audience?'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review = df.review_content[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa7706",
   "metadata": {},
   "source": [
    "### Router Chain\n",
    "For more complicated chaining i.e. routing topic-related prompts to specialized subchain.<br><br>\n",
    "![routerchain.png](../img/routerchain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define specialized subchains, subsequent prompt templates\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ff63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31680520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6010db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a default chain for when the router cannot decide where to send the input\n",
    "# i.e. if the query has nothing to do with either Physics, Math, History or Computer Science\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c79fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to route the input to the right chain\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = r\"\"\"Given a raw text input to a\\n\n",
    "language model select the model prompt best suited for the input.\\n\n",
    "You will be given the names of the available prompts and a\\n\n",
    "description of what the prompt is best suited for.\\n\n",
    "You may also revise the original input if you think that revising\\n\n",
    "it will ultimately lead to a better response from the language model.\\n\\n\n",
    "\n",
    "<< FORMATTING >>\\n\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\\n\n",
    "```json\\n\n",
    "{{{{\n",
    "    \"destination\": string \\n \"DEFAULT\" or name of the prompt to use in {destinations}\n",
    "    \"next_inputs\": string \\n a potentially modified version of the original input\n",
    "}}}}\n",
    "```C\n",
    "\n",
    "REMEMBER: The value of ‚Äúdestination‚Äù MUST match one of\n",
    "the candidate prompts listed below.\n",
    "If ‚Äúdestination‚Äù does not fit any of the specified prompts, set it to ‚ÄúDEFAULT.‚Äù\n",
    "REMEMBER: \"next_inputs\" can just be the original input\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b31c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "# check if prompt is in correct formatting\n",
    "print(router_prompt.format(input=\"What is black body radiation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee006404",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is black body radiation?',\n",
       " 'text': 'Alright, let\\'s tackle black body radiation. Here\\'s the breakdown in a clear way:\\n\\n**What it is:**\\n\\nImagine an object that *perfectly* absorbs all electromagnetic radiation (light, heat, etc.) that hits it. It doesn\\'t reflect *anything*. This theoretical object is called a \"black body.\"  \\n\\nBlack body radiation is the electromagnetic radiation (light) that a black body *emits* due to its temperature.  It\\'s not light coming *from* a source within the object, but rather light generated simply because the object is hot.\\n\\n**Key Points:**\\n\\n*   **Temperature Dependent:** The *amount* and *type* of radiation emitted depends *only* on the black body\\'s temperature.  Cooler black bodies emit mostly infrared radiation (heat you can feel). Hotter black bodies emit visible light, then eventually ultraviolet and X-rays.\\n*   **Spectrum:** The distribution of wavelengths (colors) of the emitted radiation is described by a characteristic curve called the black body spectrum. This spectrum is defined by Planck\\'s Law.\\n*   **Idealization:**  Perfect black bodies don\\'t exist in reality, but many real objects (like stars, the filament of an incandescent light bulb, and even the Earth) approximate black body behavior reasonably well.\\n\\n\\n\\nThat\\'s the core concept. Do you want me to elaborate on any specific aspect, like Planck\\'s Law or how it relates to stars?'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call the physics prompt template\n",
    "chain.invoke({\"input\": \"What is black body radiation?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2b969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is 2 + 2?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 2 + 2?',\n",
       " 'text': 'Alright, let\\'s tackle this! You\\'re right to want to break it down, even for something that seems simple. It\\'s a great habit to build for more complex problems later.\\n\\nHere\\'s how we can approach \"2 + 2\":\\n\\n**1. Understanding the Basics: What does \"addition\" mean?**\\n\\n*   Addition is combining groups of things together.  The \"+\" symbol tells us to do that.\\n*   \"2\" represents a group of two things.  Let\\'s imagine we have two apples: üçéüçé\\n*   When we add another \"2\", we\\'re adding another group of two things.  So, we have another two apples: üçéüçé\\n\\n**2. Combining the Groups:**\\n\\n*   Now, we put the two groups together: üçéüçé + üçéüçé\\n*   Let\\'s count them all: üçéüçéüçéüçé\\n\\n**3. The Answer:**\\n\\n*   We have four apples. Therefore, 2 + 2 = 4\\n\\n**Therefore, 2 + 2 = 4**\\n\\n\\n\\nI hope that breakdown was helpful! Even for a simple problem, thinking about the underlying concepts is a valuable skill. Do you have another math question you\\'d like me to help you with?'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call the math prompt template\n",
    "chain.invoke({\"what is 2 + 2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'Explain why every cell in a living organism contains DNA, focusing on the biological and genetic reasons.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, excellent question! This delves into some fundamental biology and genetics. Let\\'s break down why every cell in a living organism contains DNA. I\\'m going to structure this explanation in a way that\\'s clear, logical, and emphasizes the \"why\" behind it, much like I would approach a complex algorithm design.  I\\'m also going to highlight key concepts along the way.\\n\\n**1. The Core Principle: DNA as the Blueprint of Life**\\n\\n*   **What is DNA?** Deoxyribonucleic acid (DNA) is a molecule that carries the genetic instructions for all known living organisms and many viruses. Think of it as the master blueprint for building and operating an organism. It\\'s a long, double-helix structure composed of nucleotides (adenine, guanine, cytosine, and thymine).\\n*   **The Central Dogma:** The foundation of this explanation rests on the \"Central Dogma of Molecular Biology.\"  This describes the flow of genetic information: DNA -> RNA -> Protein.  Proteins are the workhorses of the cell ‚Äì they perform almost every function.  Without DNA, you can\\'t reliably make those proteins.\\n\\n**2. Why *Every* Cell Needs DNA: The Functional Requirements**\\n\\nLet\\'s break this down into categories, thinking about the requirements a cell *must* fulfill to survive and function.\\n\\n*   **Protein Synthesis (The Absolute Minimum):**\\n    *   **Requirement:** Every cell *must* synthesize proteins.  Proteins are involved in everything: structural support, enzymatic reactions, transport, signaling, and so much more.  No protein synthesis = no life.\\n    *   **DNA\\'s Role:** DNA contains the genes that encode these proteins.  The information in DNA is transcribed into RNA, which is then translated into proteins.  Without DNA, there\\'s no template for this process.\\n    *   **Analogy:** Imagine a factory. DNA is the master plan for all the machines and products.  Without the plan, the factory can\\'t produce anything.\\n*   **Cellular Reproduction (For Growth and Inheritance):**\\n    *   **Requirement:**  Cells divide to create new cells. This is essential for growth, repair, and reproduction (in multicellular organisms).\\n    *   **DNA\\'s Role:** When a cell divides, it *must* pass on its genetic information to the new daughter cells.  DNA is the vehicle for this inheritance.  Before division, DNA is replicated (copied) to ensure each daughter cell receives a complete set of instructions.\\n    *   **Analogy:**  Think of photocopying a document.  You need the original document (DNA) to make a copy for the new cell.\\n*   **Regulation of Cellular Processes:**\\n    *   **Requirement:** Cells need to control *when* and *how* genes are expressed (turned on or off).  This is crucial for development, responding to the environment, and maintaining homeostasis.\\n    *   **DNA\\'s Role:** DNA contains regulatory sequences that control gene expression. These sequences interact with proteins that bind to DNA and influence transcription. Without DNA, there\\'s no way to regulate these processes.\\n*   **Maintaining Cellular Identity:**\\n    *   **Requirement:** Each cell type (e.g., muscle cell, nerve cell, skin cell) needs to maintain its specific identity and function.\\n    *   **DNA\\'s Role:** DNA contains the unique genetic information that defines a cell\\'s identity.  While all cells in an organism have largely the same DNA, different genes are expressed in different cell types, leading to their specialized functions.\\n\\n**3. Addressing Potential Counterarguments & Nuances**\\n\\n*   **Mitochondrial DNA (mtDNA):**  Mitochondria, the powerhouses of the cell, have their own DNA. This is a fascinating exception, but it *still* reinforces the principle.  Mitochondria need their own DNA to function properly (producing energy).  The presence of mtDNA highlights that even organelles require genetic information.\\n*   **Red Blood Cells (Mature):** Mature mammalian red blood cells *lose* their nucleus (and therefore their DNA) during their development. This is a specialized adaptation for maximizing oxygen-carrying capacity. However, they are *derived* from cells that *did* have DNA.  They are a consequence of a process that started with DNA.\\n*   **Viruses:** Viruses are a grey area. They don\\'t always contain DNA. Some use RNA. However, the fundamental principle still applies: a genetic molecule is *required* to encode the information needed for replication and survival.\\n\\n**4. Summary & Key Takeaways (Algorithm-like Conclusion)**\\n\\nHere\\'s a concise summary, almost like a pseudocode explanation:\\n\\n```\\nFunction CellContainsDNA(organism):\\n  // Check if organism is living\\n  If organism.isLiving == False:\\n    Return False\\n\\n  // Check if cell needs to synthesize proteins\\n  If cell.needsProteinSynthesis == True:\\n    // DNA is required for protein synthesis\\n    Return True\\n\\n  // Check if cell needs to reproduce\\n  If cell.needsReproduction == True:\\n    // DNA is required for inheritance\\n    Return True\\n\\n  // Check if cell needs to regulate processes\\n  If cell.needsRegulation == True:\\n    // DNA is required for regulation\\n    Return True\\n\\n  // If none of the above, it\\'s a highly specialized case (like a mature red blood cell)\\n  // But it still originated from a cell with DNA.\\n  Return True\\n```\\n\\n**In essence, the presence of DNA in every cell is a fundamental consequence of the requirements for life. It\\'s not just *present*; it\\'s *essential* for the cell to function, reproduce, and maintain its identity.**\\n\\n\\n\\nDo you want me to elaborate on any specific aspect of this explanation, perhaps diving deeper into the mechanisms of DNA replication, transcription, or gene regulation?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# should default as no prompt template in biology exists\n",
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
